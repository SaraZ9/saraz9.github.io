<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/hugo-website/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=hugo-website/livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>AI Tank Battle Project | Sara Zhang</title>
<meta name="keywords" content="Artificial Intelligence, Reinforcement Learning, Java, Neural Networks, Machine Learning, Q-Learning, SARSA, Robocode, Autonomous Agents, Unsupervised Learning">
<meta name="description" content="This project was a hands-on exploration of Artificial Intelligence, completed as part of **CPEN 502 - Architecture for Learning Systems**. The primary objective was to develop an intelligent tank, leveraging **Reinforcement Learning (RL)** and **Neural Networks (NNs)**, to autonomously battle against explicitly programmed tanks within a game environment. Through this project, I applied machine learning techniques to design an unsupervised tank that can adapt to its environment and optimize its performance over time.">
<meta name="author" content="Sara Zhang">
<link rel="canonical" href="http://localhost:1313/hugo-website/projects/project4/">
<link crossorigin="anonymous" href="/hugo-website/assets/css/stylesheet.6556b24f602e9a2b8138c0189aebe477af3d3ac0e7daa4ebd4822a1d3e60779e.css" integrity="sha256-ZVayT2AumiuBOMAYmuvkd689OsDn2qTr1IIqHT5gd54=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/hugo-website/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/hugo-website/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/hugo-website/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/hugo-website/apple-touch-icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/hugo-website/projects/project4/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="AI Tank Battle Project" />
<meta property="og:description" content="This project was a hands-on exploration of Artificial Intelligence, completed as part of **CPEN 502 - Architecture for Learning Systems**. The primary objective was to develop an intelligent tank, leveraging **Reinforcement Learning (RL)** and **Neural Networks (NNs)**, to autonomously battle against explicitly programmed tanks within a game environment. Through this project, I applied machine learning techniques to design an unsupervised tank that can adapt to its environment and optimize its performance over time." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/hugo-website/projects/project4/" />
<meta property="og:image" content="http://localhost:1313/hugo-website/project4.png" /><meta property="article:section" content="projects" />
<meta property="article:published_time" content="2023-12-30T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-10-07T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="http://localhost:1313/hugo-website/project4.png" />
<meta name="twitter:title" content="AI Tank Battle Project"/>
<meta name="twitter:description" content="This project was a hands-on exploration of Artificial Intelligence, completed as part of **CPEN 502 - Architecture for Learning Systems**. The primary objective was to develop an intelligent tank, leveraging **Reinforcement Learning (RL)** and **Neural Networks (NNs)**, to autonomously battle against explicitly programmed tanks within a game environment. Through this project, I applied machine learning techniques to design an unsupervised tank that can adapt to its environment and optimize its performance over time."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Projects",
      "item": "http://localhost:1313/hugo-website/projects/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "AI Tank Battle Project",
      "item": "http://localhost:1313/hugo-website/projects/project4/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "AI Tank Battle Project",
  "name": "AI Tank Battle Project",
  "description": "This project was a hands-on exploration of Artificial Intelligence, completed as part of **CPEN 502 - Architecture for Learning Systems**. The primary objective was to develop an intelligent tank, leveraging **Reinforcement Learning (RL)** and **Neural Networks (NNs)**, to autonomously battle against explicitly programmed tanks within a game environment. Through this project, I applied machine learning techniques to design an unsupervised tank that can adapt to its environment and optimize its performance over time.",
  "keywords": [
    "Artificial Intelligence", "Reinforcement Learning", "Java", "Neural Networks", "Machine Learning", "Q-Learning", "SARSA", "Robocode", "Autonomous Agents", "Unsupervised Learning"
  ],
  "articleBody": " ## Project Overview This project was a hands-on exploration of Artificial Intelligence, completed as part of **CPEN 502 - Architecture for Learning Systems**. The primary objective was to develop an intelligent tank, leveraging **Reinforcement Learning (RL)** and **Neural Networks (NNs)**, to autonomously battle against explicitly programmed tanks within a game environment. Through this project, I applied machine learning techniques to design an unsupervised tank that can adapt to its environment and optimize its performance over time. Key Features and Learning Outcomes Application of Reinforcement Learning: Implemented and compared the performance of Q-Learning and SARSA algorithms, utilizing a multi-layer NN to model the state space and optimize tank actions using Backpropagation. Neural Network Design: Built a neural network with multiple layers to approximate the Q-function, replacing traditional lookup tables. This NN was tuned for optimal performance by experimenting with hyperparameters such as learning rate, momentum, and number of hidden neurons. Performance Metrics: Assessed the tank’s effectiveness by tracking win rates and total rewards over numerous rounds. Different exploration rates and discount factors were tested to understand their impact on performance and convergence. Technical Details Programming Language: Java Techniques: Q-Learning, SARSA, Neural Networks with Backpropagation Tools and Libraries: Custom-built NNs, Robocode simulator for environment interactions Project Deliverables I documented each phase of this project in a series of reports:\nAssignment 1 - Set up a basic neural network to solve simple tasks and analyzed the convergence behavior. Assignment 2 - Developed the intelligent tank, experimenting with on-policy and off-policy learning. Assignment 3 - Refined the NN-based tank, conducted hyperparameter tuning, and compared performance across different RL algorithms. These reports provide a comprehensive view of the design choices, implementation challenges, and technical insights gained throughout the project.\nRelated material You can find my project reports for more details on my approach and results:\nAssignment 1 Report Assignment 2 Report Assignment 3 Report ",
  "wordCount" : "309",
  "inLanguage": "en",
  "image":"http://localhost:1313/hugo-website/project4.png","datePublished": "2023-12-30T00:00:00Z",
  "dateModified": "2024-10-07T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Sara Zhang"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/hugo-website/projects/project4/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Sara Zhang",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/hugo-website/favicon.ico"
    }
  }
}
</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" integrity="sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js" integrity="sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
            {left: "\\begin{align}", right: "\\end{align}", display: true},
            {left: "\\begin{align*}", right: "\\end{align*}", display: true},
            {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
            {left: "\\begin{gather}", right: "\\end{gather}", display: true},
            {left: "\\begin{CD}", right: "\\end{CD}", display: true},
          ],
          throwOnError : false
        });
    });
</script>
 


</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/hugo-website/" accesskey="h" title="Sara Z.">
                <img src="http://localhost:1313/hugo-website/favicon.ico" alt="" aria-label="logo"
                    height="18"
                    width="18">Sara Z.</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/hugo-website/projects/" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/hugo-website/experience/" title="Experience">
                    <span>Experience</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/hugo-website/education/" title="Education">
                    <span>Education</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/hugo-website/tags/" title="Keywords">
                    <span>Keywords</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/hugo-website/life/" title="About Me">
                    <span>About Me</span>
                </a>
            </li>
        </ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      AI Tank Battle Project
    </h1>
    <div class="post-meta"><span title='2023-12-30 00:00:00 +0000 UTC'>December 30, 2023</span>&nbsp;&middot;&nbsp;Sara Zhang&nbsp;&middot;&nbsp;<a href="../" rel="noopener noreferrer" target="_blank">view all projects</a>

</div>
  </header> 
  <div class="post-content"><div align="center">
    <img src="project4.png" alt="cover for the project" width="600"/>
</div>
## Project Overview
This project was a hands-on exploration of Artificial Intelligence, completed as part of **CPEN 502 - Architecture for Learning Systems**. The primary objective was to develop an intelligent tank, leveraging **Reinforcement Learning (RL)** and **Neural Networks (NNs)**, to autonomously battle against explicitly programmed tanks within a game environment. Through this project, I applied machine learning techniques to design an unsupervised tank that can adapt to its environment and optimize its performance over time.
<h2 id="key-features-and-learning-outcomes">Key Features and Learning Outcomes</h2>
<ul>
<li><strong>Application of Reinforcement Learning</strong>: Implemented and compared the performance of <strong>Q-Learning</strong> and <strong>SARSA</strong> algorithms, utilizing a multi-layer NN to model the state space and optimize tank actions using <strong>Backpropagation</strong>.</li>
<li><strong>Neural Network Design</strong>: Built a neural network with multiple layers to approximate the Q-function, replacing traditional lookup tables. This NN was tuned for optimal performance by experimenting with hyperparameters such as learning rate, momentum, and number of hidden neurons.</li>
<li><strong>Performance Metrics</strong>: Assessed the tank&rsquo;s effectiveness by tracking <strong>win rates</strong> and <strong>total rewards</strong> over numerous rounds. Different exploration rates and discount factors were tested to understand their impact on performance and convergence.</li>
</ul>
<h2 id="technical-details">Technical Details</h2>
<ul>
<li><strong>Programming Language</strong>: Java</li>
<li><strong>Techniques</strong>: Q-Learning, SARSA, Neural Networks with Backpropagation</li>
<li><strong>Tools and Libraries</strong>: Custom-built NNs, Robocode simulator for environment interactions</li>
</ul>
<h2 id="project-deliverables">Project Deliverables</h2>
<p>I documented each phase of this project in a series of reports:</p>
<ol>
<li><strong>Assignment 1</strong> - Set up a basic neural network to solve simple tasks and analyzed the convergence behavior.</li>
<li><strong>Assignment 2</strong> - Developed the intelligent tank, experimenting with on-policy and off-policy learning.</li>
<li><strong>Assignment 3</strong> - Refined the NN-based tank, conducted hyperparameter tuning, and compared performance across different RL algorithms.</li>
</ol>
<p>These reports provide a comprehensive view of the design choices, implementation challenges, and technical insights gained throughout the project.</p>
<hr>
<h5 id="related-material">Related material</h5>
<p>You can find my project reports for more details on my approach and results:</p>
<ul>
<li><a href="assignment1.pdf">Assignment 1 Report</a>
</li>
<li><a href="assignment2.pdf">Assignment 2 Report</a>
</li>
<li><a href="assignment3.pdf">Assignment 3 Report</a>
</li>
</ul>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/hugo-website/tags/artificial-intelligence/">Artificial Intelligence</a></li>
      <li><a href="http://localhost:1313/hugo-website/tags/reinforcement-learning/">Reinforcement Learning</a></li>
      <li><a href="http://localhost:1313/hugo-website/tags/java/">Java</a></li>
      <li><a href="http://localhost:1313/hugo-website/tags/neural-networks/">Neural Networks</a></li>
      <li><a href="http://localhost:1313/hugo-website/tags/machine-learning/">Machine Learning</a></li>
      <li><a href="http://localhost:1313/hugo-website/tags/q-learning/">Q-Learning</a></li>
      <li><a href="http://localhost:1313/hugo-website/tags/sarsa/">SARSA</a></li>
      <li><a href="http://localhost:1313/hugo-website/tags/robocode/">Robocode</a></li>
      <li><a href="http://localhost:1313/hugo-website/tags/autonomous-agents/">Autonomous Agents</a></li>
      <li><a href="http://localhost:1313/hugo-website/tags/unsupervised-learning/">Unsupervised Learning</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="http://localhost:1313/hugo-website/">Sara Zhang</a></span> ·     
    <span>
    Powered by 
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/pmichaillat/hugo-website/" rel="noopener" target="_blank">a modified version</a>
         of 
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>
</html>
